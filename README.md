explode
现在先进行一列转多行的操作，这里就用到了explode()函数，将第二列tim中的数据用逗号切分并成为第三列，操作如下
select id,tim,single_tim 
from test.a lateral view explode(split(tim,',')) t as single_tim

id	tim	single_tim
a,b,c,d	2:00,3:00,4:00,5:00	2:00
a,b,c,d	2:00,3:00,4:00,5:00	3:00
a,b,c,d	2:00,3:00,4:00,5:00	4:00
a,b,c,d	2:00,3:00,4:00,5:00	5:00
f,b,c,d	1:10,2:20,3:30,4:40	1:10
f,b,c,d	1:10,2:20,3:30,4:40	2:20
f,b,c,d	1:10,2:20,3:30,4:40	3:30
f,b,c,d	1:10,2:20,3:30,4:40	4:40
Time taken: 51.289 seconds, Fetched: 8 row(s)

np.arange()
函数返回一个有终点和起点的固定步长的排列，如[1,2,3,4,5]，起点是1，终点是5，步长为1。
参数个数情况： np.arange()函数分为一个参数，两个参数，三个参数三种情况
1）一个参数时，参数值为终点，起点取默认值0，步长取默认值1。
2）两个参数时，第一个参数为起点，第二个参数为终点，步长取默认值1。
3）三个参数时，第一个参数为起点，第二个参数为终点，第三个参数为步长。其中步长支持小数

 

复制代码
一个参数 默认起点0，步长为1 输出：[0 1 2]
a = np.arange(3)
 
两个参数 默认步长为1 输出[3 4 5 6 7 8]
a = np.arange(3,9)

三个参数 起点为0，终点为3，步长为0.1 输出[ 0.   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4 1.5  1.6  1.7  1.8  1.9  2.   2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9]
a = np.arange(0, 3, 0.1)
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



训练集
这个是最好理解的，用来训练模型内参数的数据集，Classfier直接根据训练集来调整自身获得更好的分类效果

验证集
用于在训练过程中检验模型的状态，收敛情况。验证集通常用于调整超参数，根据几组模型验证集上的表现决定哪组超参数拥有最好的性能。

同时验证集在训练过程中还可以用来监控模型是否发生过拟合，一般来说验证集表现稳定后，若继续训练，训练集表现还会继续上升，但是验证集会出现不升反降的情况，这样一般就发生了过拟合。所以验证集也用来判断何时停止训练

测试集
测试集用来评价模型泛化能力，即之前模型使用验证集确定了超参数，使用训练集调整了参数，最后使用一个从没有见过的数据集来判断这个模型是否Work。

三者区别
形象上来说训练集就像是学生的课本，学生 根据课本里的内容来掌握知识，验证集就像是作业，通过作业可以知道 不同学生学习情况、进步的速度快慢，而最终的测试集就像是考试，考的题是平常都没有见过，考察学生举一反三的能力。

为什么要测试集
训练集直接参与了模型调慘的过程，显然不能用来反映模型真实的能力，这样一些 对课本死记硬背的学生(过拟合)将会拥有最好的成绩，显然不对。同理，由于验证集参与了人工调参(超参数)的过程，也不能用来最终评判一个模型，就像刷题库的学生也不能算是学习好的学生是吧。所以要通过最终的考试(测试集)来考察一个学(模)生(型)真正的能力。

但是仅凭一次考试就对模型的好坏进行评判显然是不合理的，所以接下来就要介绍交叉验证法

交叉验证法
交叉验证法的作用就是尝试利用不同的训练集/测试集划分来对模型做多组不同的训练/测试，来应对单词测试结果过于片面以及训练数据不足的问题。

====================================================================================================================
a=copy.deepcopy() 拷贝出来了就是独立的个体，原来被拷贝的对象即使发生改变了,a也不会变


在Logistic Regression中，我们定义的loss function，即要去minimize的对象，是所有example(样本点)的output(  )和实际target(  )在Bernoulli distribution(两点分布)下的cross entropy(交叉熵)总和

